{"content_00":"16\n© Автор(и).\nСтаття поширюється на умовах ліцензії CC BY 4.0\nDOI: 10.20535/kpisn.2021.1.231205\nУДК 004.942:519.216.3\nР.Л. Пантєєв1, О.Л. Тимощук2, В.Г. Гуськова2, П.І. Бідюк2* \n1Національний авіаційний університет, Київ, Україна\n2КПІ ім. Ігоря Сікорського, Київ, Україна \n*corresponding author: pbidyuke_00@ukr.net \nМЕТОДИ ФІЛЬТРАЦІЇ ДАНИХ У СИСТЕМАХ ПІДТРИМКИ ПРИЙНЯТТЯ РІШЕНЬ\nПроблематика. Більшість сучасних динамічних процесів в економіці, фінансах, екології, технологіях і ба-\nгатьох інших галузях досліджень мають нелінійний нестаціонарний характер на коротких і довгих часових \nінтервалах. Тому для їх поглибленого аналізу необхідно створити спеціалізований сучасний високорозвинений \nінструментарій попередньої обробки даних, моделювання, оцінювання станів і параметрів динамічних систем, \nпрогнозування їх розвитку задля використання у системах підтримки прийняття рішень (СППР). \nМета дослідження. По-перше, попередньо проаналізувати сучасні методи фільтрації статистичних й експе-\nриментальних даних. Розглянути актуальні методи фільтрації на основі ймовірнісного Баєсового підходу, \nякі вможливлюють підготовку даних до побудови адекватних моделей, обчислення високоякісних оцінок \nстанів і короткострокових прогнозів розвитку динамічних систем в умовах стохастичних збурень і похибок \nвимірювання. \nМетодика реалізації. Для реалізації сучасних методів фільтрації використовують моделювання, оптимізаційні \nпроцедури, ймовірнісні Баєсові методи аналізу даних; застосовують імітаційне моделювання для оціню-\nвання параметрів і базу на основі статистичних критеріїв для дослідження якості проміжних й остаточних \nрезультатів у межах СППР.\nРезультати дослідження. Розглянуто множину методів фільтрації даних, які використовують разом із моделя-\nми, що формально описують динаміку вибраних процесів. Запропоновано методику реалізації ймовірнісного \nБаєсового фільтра, яка ґрунтується на сучасних методах статистичного аналізу даних, зокрема належному \nзастосуванні методів імітаційного моделювання. \nВисновки. Створення ефективних засобів моделювання, оцінювання станів і прогнозування динаміки не-\nлінійних нестаціонарних процесів у різних галузях діяльності дає можливість якісно оцінювати параметри \nдосліджуваних систем й обчислювати коротко- та середньострокові прогнози їхнього розвитку. Розгляну-\nті засоби оптимальної калманівської та ймовірнісної Баєсової фільтрації забезпечують коректний аналіз \nнелінійних нестаціонарних процесів, обчислення прогнозів і підтримку прийняття управлінських рішень \nна основі оцінок прогнозів. \nКлючові слова: аналіз даних; нелінійні нестаціонарні процеси; методи оптимальної фільтрації; методи ймо-\nвірнісної фільтрації; імітаційне моделювання.  \nВступ\nОцінювання параметрів і станів дина-\nмічних систем \u2013 актуальна задача, результати \nрозв\u2019язання якої застосовують у дослідженні \nпроцесів технічних систем, фізичних дослі-\nдженнях, діагностичних системах медичного \nпризначення, економіці, фінансах, біотехно-\nлогіях, екології тощо [1, 2]. Попри значні нау-\nкові досягнення у цьому напрямі, дослідники \nдосі шукають нові методи оцінювання пара-\nметрів і станів досліджуваних об\u2019єктів й удо-\nсконалюють наявні. Прикладами таких мето-\nдів є цифрова та оптимальна фільтрації, які ще \nв середині минулого століття набули широкого \nзастосування в технічних системах, а з середи-\nни 1970-х років їх почали застосовувати в си-\nстемах обробки фінансово-економічних даних, \nфізичних експериментах й інших інформа-\nційних технологіях [3, 4]. Зазвичай апробацію \nметодів оцінювання параметрів і станів дина-\nмічних систем виконують у межах відповід-\nних СППР, які є зручним інструментом ана-\nлізу даних й експертних оцінок і генерування \nальтернативних рішень на його основі. Мета \nстворення СППР \u2013 надавати користувачу \nможливість прискорено досліджувати вибрані \nпроцеси та використовувати множину мето-\nдів попередньої обробки даних, оцінювання \nструктури та параметрів моделей; генерувати \nальтернативні рішення та вибирати кращі ре-\nзультати на основі об\u2019єктивного добору альтер-\nнативи за допомогою критеріїв якості. \nДо задач аналізу даних належить оці-\nнювання невимірюваних змінних стану, що \nзмінюються в часі, із застосуванням вимірів \nІНФОРМАЦІЙНІ ТЕХНОЛОГІЇ, СИСТЕМНИЙ АНАЛІЗ ТА КЕРУВАННЯ\n17ІНФОРМАЦІЙНІ ТЕХНОЛОГІЇ, СИСТЕМНИЙ АНАЛІЗ ТА КЕРУВАННЯ\nінших змінних за наявності похибок дискрет-\nних вимірів. Похибки вимірювання є завжди, \nколи реєструють вимірювальну інформацію. \nВони зумовлені недосконалістю вимірюваль-\nних приладів, зовнішніми шумовими впли-\nвами на лініях передачі сигналів і скінченною \nдовжиною розрядної сітки аналого-цифрових \nперетворювачів і комп\u2019ютерів [5]. Коли дані \nзбирають вручну, похибки вимірювання будуть \nіснувати внаслідок помилок, яких припускають-\nся учасники процесу збору даних [6]. \nВипадкові збурення станів динамічних \nсистем також негативно впливають на якість \nоцінювання станів. Ця задача потребує уваги \nдослідників, які працюють над зменшенням \nвпливу випадкових збурень станів на значен-\nня оцінок змінних на виході систем. Шуми/\nпохибки вимірювання і збурення станів вра-\nховують явно за допомогою математичних мо-\nделей динамічних систем у просторі станів, які \nособливо широко застосовують для розв\u2019язу-\nвання задач прогнозування та синтезу систем \nкерування динамічними об\u2019єктами. Але, крім \nтехнічних систем автоматичного/автоматизо-\nваного керування, такі моделі застосовують \nі для оцінювання та прогнозування станів до-\nсліджуваних систем в економіці та фінансах, \nекології, кліматології тощо. \nУ задачах моделювання часових рядів \nу просторі станів основним поняттям є вектор \nстану, який містить усю необхідну для опису \nспостережуваної системи інформацію в кон-\nкретній задачі. Наприклад, у задачах стеження \nза рухом об\u2019єктів ця інформація може стосу-\nватися координат, швидкості та прискорення \nоб\u2019єкта; в економетричних застосуваннях \u2013 \nдослідження ціни активів, аналізу відсотко-\nвих ставок, рівня інфляції, рівня виробництва \nВВП, волатильності процесів тощо. Вектор \nвимірів представляє зашумлені спостережен-\nня, пов\u2019язані з вектором стану. Він може мати \nменшу розмірність, ніж вектор стану через \nневимірювані компоненти. Прикладом неви-\nмірюваної компоненти може бути обсяг капі-\nталу, який періодично передають в офшори; \nтемпература всередині вала двигуна з високою \nшвидкістю обертання, що внеможливлює вста-\nновлення у ньому датчика; температура всере-\nдині високотемпературного розплаву [6]. \nЗа використання ймовірнісних методів \nаналізу даних для формування ймовірнісно-\nго висновку щодо стану динамічної систе-\nми необхідно будувати принаймні дві моделі. \nПо-перше, модель, що описує зміну стану \nсистеми в часі (модель динаміки системи чи \nзмінних її стану); по-друге, модель, що пов\u2019я-\nзує зашумлені виміри компонент вектора ста-\nну з процесами похибок (модель вимірів). Такі \nмоделі в просторі станів мають бути також \nдоступними для дослідження та застосування \nв імовірнісній формі [7, 8]. Побудова моделей \nтакого типу зазвичай є предметом окремого \nдослідження у кожній конкретній галузі. \nЗавданням лінійної та нелінійної фільтра-\nції є формування/обчислення статистичного \nчи ймовірнісного висновків щодо стану системи \nз огляду на наявні виміри. В межах Баєсово-\nго підходу до аналізу даних це відбувається об-\nчисленням або апроксимацією апостеріорного \nрозподілу вектора стану за умови використан-\nня всіх наявних на момент обчислення вимірів \nй оцінок невимірюваних компонент. Оскільки \nфункція розподілу ймовірностей вимірів прак-\nтично містить усю доступну статистичну інфор-\nмацію про досліджуваний об\u2019єкт, її оцінювання \nє досить повним розв\u2019язком задачі оцінювання \nстану, прогнозування його розвитку та підтрим-\nки прийняття управлінських рішень [8]. \nНижче розглянемо сучасні методи опти-\nмальної та ймовірнісної нелінійних фільтрацій \nстатистичних/експериментальних даних й особ-\nливості їх застосування в розв\u2019язанні задачі \nоцінювання станів динамічних систем, зокрема \nсупроводженні рухомих об\u2019єктів. Буде обґрунто-\nвано створення СППР для моделювання та оці-\nнювання траєкторії рухомого об\u2019єкта на основі \nсучасних методів фільтрації, а також застосу-\nвання алгоритму фільтрації Баєсового типу \n(\u201cгранулярного фільтра\u201d, який дедалі ширше \nзастосовують у розв\u2019язуванні задач оцінювання \nта прогнозування станів динамічних систем). \nПостановка задачі \nМетою дослідження є: розглянути особли-\nвості певних підходів до розв\u2019язання задач лі-\nнійної та нелінійної фільтрацій статистичних/\nекспериментальних даних, які забезпечують об-\nчислення оптимальних оцінок станів досліджу-\nваних об\u2019єктів і короткострокове прогнозуван-\nня їхнього розвитку. Виконати аналіз і навести \nприклади програмної реалізації методу грану-\nлярної Баєсової фільтрації, а також розглянути \nприклад розв\u2019язання задачі позиціювання робо-\nта з використанням імовірнісного фільтра. \n18 KPI Science News 2021 / 1\nПідходи до розв\u2019язування задач лінійної та \nнелінійної фільтрацій \nКласичними підходами до розв\u2019язання \nзадач лінійної та нелінійної фільтрацій вважа-\nються, зокрема, подані нижче. Задачу одночас-\nного оцінювання стану та прогнозування руху \nдинамічної системи розв\u2019язують за допомо-\nгою методів оптимальної фільтрації, зокрема \nфільтра Калмана (ФК). Нині існує кілька мо-\nдифікацій ФК, які забезпечують розв\u2019язання \nзадач згладжування даних, обчислення оцінок \nпрогнозів на основі оптимальних оцінок век-\nтора стану; оцінювання невимірюваних ком-\nпонент вектора стану, а також певних пара-\nметрів математичних моделей. \n1. Оптимальний ФК \u2013 обчислює апосте-\nріорний розподіл для лінійних Гаусових систем \nрекурсивним оновленням скінченно-вимір-\nних статистичних даних. ФК є оптимальним \nу своєму класі (лінійних Гаусових систем), але \nобмеження на його практичне застосування є \nдостатньо жорсткими [9, 10]. \nРівняння фільтрації для вільної динаміч-\nної системи (без урахування можливих керів-\nних впливів), яке ґрунтується на моделі процесу \nв просторі станів, можна записати так:\n[ ]ˆ ˆ ˆ( ) ( 1) ( ) ( ) ( 1)k k k k k= − + − −x A x K z H A x ,\nде [ ])1(ˆ)()()1(ˆ)(ˆ --+-= kkkkk xAHzKxAx  \u2013 оптимальна оцінка вектора стану \nx(k) у момент часу k; A \u2013 матриця динаміки \nпроцесу (перехідна матриця); z(k) \u2013 вектор ви-\nмірів змінних на виході об\u2019єкта; H \u2013 матриця \nвимірів; K(k) \u2013 оптимальний матричний кое-\nфіцієнт фільтра, який обчислюється за мінімі-\nзації функціонала:\n{ }ˆ ˆmin [ ( ) ( )] [ ( ) ( )]TJ E k k k k= − −\nK\nx x x x ,\nтобто за мінімуму математичного сподівання \nсуми квадратів похибок оцінювання вектора \nстану процесу (оптимальне значення K визнача-\nється розв\u2019язком відповідного рівняння Ріккаті). \nАлгоритм оцінювання вектора стану також дає \nможливість оцінювати однокроковий прогноз \nкомпонент вектора стану: \n)|(ˆ)|1(ˆ kkkk xAx =+ ,\nза допомогою якого можна отримати оцінки \nпрогнозів на довільну кількість S кроків: \n)|(ˆ)|(ˆ kkksk s xAx =+ .\nЦінність фільтра полягає в його ролі алго-\nритму згладжування та прогнозування з ураху-\nванням невизначеностей параметрів (матема-\nтичне сподівання та коваріація) досліджуваних \nстохастичних процесів збурення станів і по-\nхибок вимірів, а тому його введення у СППР \nнадає системі додаткові можливості. До того ж \nадаптивний фільтр дає змогу в реальному часі \nоцінювати статистичні характеристики збу-\nрення стану та похибок вимірів, які не завжди \nможна визначити апріорно. \n2. Розширений фільтр Калмана (РФК). \nУ цьому випадку для оцінювання станів нелі-\nнійних негаусових моделей застосовують алго-\nритм фільтрації Калмана до лінеаризованої мо-\nделі досліджуваного об\u2019єкта з Гаусовим шумом \nі тими ж моментами першого та другого поряд-\nків. РФК апроксимує нелінійну функцію, ви-\nкористовуючи її розклад у ряд Тейлора другого \nпорядку. Недоліками цього підходу є, зокрема, \nпідміна реальної функції розподілу щільності \nнормальною та використання наближеної мо-\nделі динаміки [9, 10]. Іноді можуть виникати \nпроблеми зі збіжністю алгоритму фільтрації. \n3. Модифікований РФК. Складнішим \nтипом нелінійності є залежність неперервних \nзмінних стану X(t) від можливих дискретних \nзмінних D(k), k = 0, 1, 2, ..., які можуть мати \nнестаціонарні розподіли, відмінні від розподілу \nнеперервної змінної. Через це виникає задача \nформулювання гіпотез для всіх можливих ва-\nріантів значень дискретних змінних. Кількість \nтаких гіпотез може зростати експоненційно \nза збільшення довжини дискретної послідов-\nності, що призводить до значних обчислю-\nвальних проблем. Для такого випадку запро-\nпоновано модифікацію РФК, яка передбачає \nвведення випадкової змінної H(k), кожне зна-\nчення якої відповідає одній із можливих гіпо-\nтез [11]. Розподіл H(k) відповідає правдоподіб-\nності вибраної гіпотези. У процесі реалізації \nтакого фільтра розглядають усі комбінації зна-\nчень H(k) і D(k + 1), що призводить до аналізу \nсуміші, яка містить K × |D| компонент. Кожна \nнова гіпотеза кондиціонується (нормується) \nна вимірах Y(k + 1), і завдяки Баєсовому кон-\nдиціонуванню корегуються вагові коефіцієнти \nсуміші та параметри багатовимірних гаусіан.\n4. Фільтр на основі нелінійного пере-\nтворення розподілу ймовірностей (unscented \ntransform) даних. Реалізація такого фільтра \nґрунтується на тому принципі, що множину \nдискретних вимірів можна використати для \n19ІНФОРМАЦІЙНІ ТЕХНОЛОГІЇ, СИСТЕМНИЙ АНАЛІЗ ТА КЕРУВАННЯ\nпараметризації середнього значення та кова-\nріації. \nІнформація, необхідна для оцінювання \nсереднього значення та коваріації, міститься \n(кодується) у множині точок (дискретному роз-\nподілі вимірів), які називають сигма-точками \n(sigma points). Цей розподіл можна трансфор-\nмувати в інший (необхідний), застосовуючи \nнелінійне перетворення до кожного виміру. \nСереднє значення та коваріацію отриманого \nнового розподілу становлять оцінки, необхідні \nдля алгоритму фільтрації. На відміну від РФК, \nу якому нелінійна функція апроксимується лі-\nнійною, принципова перевага цього підходу \nполягає в повному використанні наявної не-\nлінійної функції (моделі даних). Тобто немає \nнеобхідності застосовувати лінеаризацію, яка \nпотребує диференціювання нелінійної функції, \nщо сприяє підвищенню якості оцінок на виході \nфільтра. Водночас спрощується практична ре-\nалізація фільтра, оскільки непотрібно будувати \nта використовувати відповідну матрицю Якобі. \nЗагалом такий алгоритм оцінювання ге-\nнерує результати, еквівалентні за якістю тим, \nщо генерує оптимальний ФК для лінійних \nсистем, але його використовують для неліній-\nних систем без застосування лінеаризації, яку \nнеобхідно виконувати для РФК. Аналітично \nпоказано, що якість фільтрації за такої умови \nперевищує якість РФК і може порівнюватись \nіз якістю функціонування Гаусового фільтра \nдругого порядку [12, 13]. Водночас метод не об-\nмежується Гаусовим розподілом шумових ком-\nпонент вимірів. \n5. Фільтр матеріальних точок (point mass \nfilter, або PMF). У цьому випадку на простір \nстанів накладається вибрана сітка, на якій \nрекурсивно обчислюється апостеріорний роз-\nподіл станів. Цей фільтр придатний для будь-\nяких нелінійних і негаусових моделей і здатний \nпредставити з прийнятною точністю будь-\nякий апостеріорний розподіл. Головними не-\nдоліками цього методу є великий розмір сітки \nза високого порядку простору станів і квадра-\nтичність обчислювальної складності алгоритму \nоцінювання щодо розміру сітки. \n6. Гранулярний (багаточастинковий, particle \nfilter (PF)) фільтр. Цей фільтр подібний до філь-\nтра матеріальних точок, але використовує \nадаптивну стохастичну сітку, що автоматично \nобирає релевантні точки (значення) в просто-\nрі станів. На відміну від фільтра матеріальних \nточок, алгоритм гранулярної фільтрації (ГФ) \nза складністю є лінійним щодо розміру сітки \nобчислень. Перевагами такого фільтра є мож-\nливість застосування майже до довільного типу \nрозподілу даних, відносна простота чисельної \nреалізації та практичного використання. Грану-\nлярні Баєсові фільтри будуть розглянуті в цій \nроботі докладніше. \nЗагальна форма Баєсового алгоритму \nоцінювання стану\nДинаміку нелінійної стохастичної систе-\nми можна описати дискретними рівняннями \nв просторі станів:\n\u2013 рівнянням спостережень:\nx f x w( ) [ ( ), ( )]k k k= − −1 1 ,           (1)\n\u2013 рівнянням вимірів: z h x v( ) [ ( ), ( )]k k k= , (2) \nде x(k) \u2013 вектор стану досліджуваної системи \nз довільним негаусовим розподілом Px(k); z(k) \u2013 \nвектор дійсних вимірів, які в загальному ви-\nпадку можуть бути комплексними числами, \nперетвореними на дійсні; w(k) \u2013 вектор ви-\nпадкових зовнішніх збурень із відомою щільні-\nстю розподілу ймовірностей Pw(k); v(k) \u2013 вектор \nпохибок (шуму) вимірів із відомою щільністю \nрозподілу Pv(k); f, h \u2013 нелінійні детерміновані \nфункції; k \u2013 0, 1, 2, 3, ... \u2013 дискретний час. \nВипадкові збурення стану та шум вимірів за-\nзвичай уводять у рівняння (1) і (2) в адитивній \nформі, що спрощує оцінювання параметрів мо-\nделі та дає змогу побудувати модель високого \nступеня адекватності. За необхідності в модель \n(1) і (2) можна додати вектор керівних впливів \nu(k). Перший вимір z(1) дає можливість оціни-\nти стан x(1), а з надходженням нових вимірів \nбудуть оцінюватись майбутні стани. Введемо \nпозначення x x x x( : ) { ( ), ( ),..., ( )}1 1 2k k=  \u2013 пос-\nлідовність значень вектора станів; аналогічно \nможна позначити інші змінні розглянутої мо-\nделі в просторі станів. \nУ термінах умовної щільності розподілу \nймовірностей подана вище модель у просторі \nстанів може бути записана так: \nx x x( ) [ ( ) | ( )]k P k k∼ −1 ;\nz z z( ) [ ( ) | ( )]k P k k∼ −1 .\nЗ погляду Баєсового підходу до обробки \nданих задачею оцінювання стану є генерування \n(оцінювання) апостеріорної щільності розподі-\nлу P k k[ ( ) | ( : )]x z 1  на основі послідовності ви-\n20 KPI Science News 2021 / 1\nмірів z z z z( : ) { ( ), ( ), ..., ( )}1 1 2k k= . Рівняння (1) \nзадає прогнозну умовну перехідну щільність \nімовірностей P k k k[ ( ) | ( ), ( : )]x x z- -1 1 1  на ос-\nнові значення попереднього стану та всіх ви-\nмірів від першого до P k k k[ ( ) | ( ), ( : )]x x z- -1 1 1 . Рівняння \nспостережень (2) визначає функцію правдопо-\nдібності для поточного спостереження за умо-\nви відомого поточного стану P k k[ ( ) | ( : )]z x 1 . \nАпріорну ймовірність стану, P k k[ ( ) | ( : )]x z 1 1- , \nможна визначити за формулою (теоремою) \nБаєса так: \nP k k\nP k k k\nP k k\n[ ( ) | ( : )]\n[ ( ) | ( ), ( : )]\n[ ( ) | ( :\nx z\nx x z\nx z\n1 1\n1 1 1\n1 1 1\n− =\n= − −\n− −\n∫\n)] ( )d kx −1        (3)\nЩільність розподілу ймовірностей на попередньо-\nму кроці визначається як P k k[ ( ) | ( : )].x z- -1 1 1  \nНа кроці корегування оцінки стану обчислю-\nють функцію щільності розподілу: \nP k k\nc P k k P k k\n[ ( ) | ( : )]\n[ ( ) | ( : )] [ ( ) | ( : )],\nx z\nz x x z\n1 1\n1 1 1 1\n− =\n= − −  (4)\nде c \u2013 нормувальна константа. \nЗадача фільтрації полягає в рекурсивному \nобчисленні перших двох моментів вектора x(k) \nза умови відомих вимірів z(1 : k). Для деякого \nзагального типу розподілу P(x) ця задача поля-\nгає в рекурсивному оцінюванні математичного \nсподівання будь-якої (фактичної) функції від \nx(k), наприклад, g\np x\n( )\n( )\nx  із використанням \nрівнянь (3) і (4) й обчисленням інтеграла: \ng g P d\np x\n( ) ( ) ( )\n( )\nx x x x= ∫ .          (5)\nОднак цей інтеграл неможливо взяти \nв замкненій формі в разі аналізу загальних ба-\nгатовимірних розподілів, а тому його значення \nнеобхідно апроксимувати відомими методами \n[14, 15]. \nРівняння (1) і (2) часто застосовують із ади-\nтивними випадковими Гаусовими складниками \nтакого типу: \nx f x w( ) [ ( )] ( )k k k= − + −1 1 ,          (6) \nz h x v( ) [ ( )] ( )k k k= + ,              (7)\nде w(k) і v(k) \u2013 випадкові векторні процеси, \nщо представляються в імітаційній моделі Гау-\nсовими випадковими змінними з нульовим \nсереднім значенням і коваріаційними матри-\nцями Q(k) і R(k) відповідно. Початковий стан \nx(0) також моделюється випадковими величи-\nнами, незалежними від обох шумових склад-\nників із середнім значенням, 0x̂ , і коваріацій-\nною матрицею P xx\n0 . \nПрипустимо, що нелінійні детерміновані \nфункції f, h і коваріаційні матриці Q і R \u2013 ста-\nціонарні, тобто їхні параметри не залежать від \nчасу. Тепер прогнозну щільність можна подати \nтак:\nP k k k\nk k\n[ ( ) | ( ), ( : )]\n( ( ); ( ( )), )\nx x z\nx f x Q\n− − =\n= −\n1 1 1\n1Ν          (8)\nде Ν Σ( ; , )t τ  \u2013 багатовимірний Гаусів розподіл, \nякий у загальному випадку описується виразом \nΝ Σ\nΣ\nΣ\n( , , )\n( )\nexp [ ] ( ) [ ]\nt\nt t\nk\nT\nτ\nπ\nτ τ\n=\n− − −\n\n\n\n\n\n−\n1\n2\n1\n2\n1 .         (9)\nРівняння (3), яке визначає апріорну ймо-\nвірність, можна представити так [16]: \nP k k\nk k\nP k k d\n[ ( ) | ( : )]\n[ ( ); ( ( )), ]\n[ ( ) | ( : )]\nx z\nx f x Q\nx z x\n1 1\n1\n1 1 1\n− =\n= −\n− −\n∫ Ν\n( )k −1 .      (10) \nСподівання величини t для Гаусового роз-\nподілу Ν Σ( ; ( ), )t f τ  можна записати так [16\u201319]: \nE t d{ } ( ; ( ), ) ( )t t f t f= =∫ Ν Στ τ .       (11)\nЗгідно з рівнянням (10), математичне спо-\nдівання вектора стану можна записати так: \nE k kx z( ) | ( : )1 1−{ } =\n= − =∫ x x z x( ) [( ( ) | ( : )] ( )k P k k d k1 1\n= − − − −{ }∫∫ x x f x Q x z x x( ) [ ( ); ( ( )), ] [ ( ) | ( : )] ( ) ( )k k k P k k d k d kΝ 1 1 1 1 1 =\n= − − − −{ }∫∫ x x f x Q x z x x( ) [ ( ); ( ( )), ] [ ( ) | ( : )] ( ) ( )k k k P k k d k d kΝ 1 1 1 1 1 =\n= −{ } − − −∫∫ x x f x Q x x z x( ) [ ( ); ( ( )), ] ( ) [ ( ) | ( : )] ( )k k k d k P k k d kΝ 1 1 1 1 1 =\n= −{ } − − −∫∫ x x f x Q x x z x( ) [ ( ); ( ( )), ] ( ) [ ( ) | ( : )] ( )k k k d k P k k d kΝ 1 1 1 1 1 =\n= − − − −∫ f x x z x( ( )) [( ( ) | ( : )] ( ).k P k k d k1 1 1 1 1  (12)\n21ІНФОРМАЦІЙНІ ТЕХНОЛОГІЇ, СИСТЕМНИЙ АНАЛІЗ ТА КЕРУВАННЯ\nУ виразі (12) використано рівняння (11) \nдля оцінювання внутрішнього інтеграла. Запи-\nшемо розподіл вектора стану для моменту часу \nk \u2013 1 із урахуванням наявних вимірів:\n[ ( 1) | (1 : 1)]\nˆ( ( 1); ( 1| 1)), ( 1 | 1))\nP k k\nk k k k k\n− − =\n= Ν − − − − −xx\nx z\nx x P , (13)\nде )1|1(ˆ -- kkx  і Pxx( | )k k- -1 1  \u2013 оцінки се-\nреднього значення для вектора стану та кова-\nріаційної матриці для x(k \u2013 1) за наявності ви-\nмірів z(1 : k \u2013 1). Оцінки середнього значення \nта коваріації ( )1|(ˆ -kkx  і Pxx( | )k k -1 ) для x(k) \nза наявності спостережень, z(1 : k \u2013 1), можна \nотримати за допомогою рівняння (12) як\nˆ( | 1) ( ( 1)) ( ( 1);\nˆ ( 1 | 1), ( 1 | 1)) ( 1)\nk k k k\nk k k k d k\n− = − Ν −\n− − − − −\n∫\nxx\nx f x x\nx P x , (14) \nа також\n( | 1)\n( ( 1)) ( ( 1)) ( ( 1);\nˆ( 1 | 1), ( 1 | 1)) ( 1)\nˆ ˆ( | 1) ( | 1).\nT\nT\nk k\nk k k\nk k k k d k\nk k k k\n− = +\n+ − − Ν −\n− − − − − −\n− − −\n∫\nxx\nxx\nP Q\nf x f x x\nx P x\nx x  (15) \nОчікуване значення вектора z(k) за наяв-\nності x(k) і z(1 : k \u2013 1) можна отримати так: \nE k k kz x z( ) | ( ), ( : )1 1−{ } =\n= −∫ z x z x( ) [( ( ) | ( : )] ( )k P k k d k1 1 .   (16)\nЯкщо використати Гаусову апроксимацію \nдля розподілу P k k[ ( ) | ( : )]x z 1 1- , який зада-\nється виразом \n[ ( ) | (1 : 1)] ( ( );\nˆ( | 1), ( | 1)),\nP k k k\nk k k k\n− = Ν\n− −xx\nx z x\nx P         (17)\nто можна отримати оцінку )1|(ˆ -kkz  \nяк вираз для математичного сподівання \nE k k ky x z( ) | ( ), ( : )1 1−{ } через інтеграл: \nˆ ( | 1)\nˆ( ) ( ( ); ( | 1),\n( | 1)) ( )\nˆ( ( )) ( ( ); ( | 1),\n( | 1)) ( ).\nk k\nk k k k\nk k d k\nk k k k\nk k d k\n− =\n= Ν −\n− =\n= Ν −\n−\n∫\n∫\nxx\nxx\nz\nz x x\nP x\nh x x x\nP x      (18)\nЯкщо позначити векторну похибку \nоцінювання вектора вимірів ˆ( | 1) ( ( )) ( | 1)y k k k k k− = − −e h x z\nˆ( | 1) ( ( )) ( | 1)y k k k k k− = − −e h x z , то можна записати вираз \nдля оцінювання коваріації вектора z(k) за наяв-\nності x(k), z(1 : k \u2013 1):\n{ }\n( | 1)\n[ ( | 1)) ( ( | 1)]\n( ( )) ( ( )) ( ( );\nˆ( | 1), ( | 1)) ( )\nˆ ˆ( | 1) ( | 1).\ny y T\nT\nT\nk k\nE k k k k\nk k k\nk k k k d k\nk k k k\n− =\n= − − =\n= + Ν\n− − −\n− − −\n∫\nyy\nxx\nP\ne e\nR h x h x x\nx P x\ny y   (19) \nЗа аналогією можна оцінити матрицю вза-\nємної коваріації Pxy ( | )k k -1 ) за виразом\n{ }\n( | 1)\nˆ[ ( ) ( | 1)] [ ( | 1)]\n( ) ( ( )) ( ( );\nˆ( | 1), ( | 1)) ( )\nˆ ˆ( | 1) ( | 1).\ny T\nT\nT\nk k\nE k k k k k\nk k k\nk k k k d k\nk k k k\n− =\n= − − − =\n= Ν\n− − −\n− − −\n∫\nxy\nxx\nP\nx x e\nx h x x\nx P x\nx y  (20) \nЗагалом ФК можна застосувати до майже \nбудь-якої динамічної системи, поданої \nв просторі станів, із адитивними Гаусовими \nвипадковими процесами в обох рівняннях \nнезалежно від нелінійностей. Однак за такої \nумови можуть виникнути труднощі зі збіжністю \nалгоритму фільтрації. Але можливо побудувати \nГаусову апроксимацію апостеріорної щільності \nP k k( ( | ))x  із середнім значенням і коваріацією, \nякі визначаються так [16]: \nˆ ˆ( | ) ( | 1)\nˆ( )[ ( ) ( | 1)],\nk k k k\nk k k k\n= − +\n+ − −\nx x\nK z z           (21)\nP P K P Kxx xx yy( | ) ( | ) ( ) ( )k k k k k kT= − −1 , (22)\nде оптимальний коефіцієнт фільтра визнача-\nється за\nK P Pxy yy( ) ( | ) [ ( | )] .k k k k k= − − −1 1 1    (23) \nЗазначимо, що єдина апроксимація, яку \nбуло використано в наведених вище викладках, \nстосується моделювання шумових складників \nадитивними Гаусовими послідовностями; об-\nчислення оцінок )|(ˆ kkx  і Pxx ( | )k k  викону-\nється без апроксимації. Однак для практич-\nної реалізації розглянутого фільтра необхідно \nотримати процедури обчислення інтегралів \n22 KPI Science News 2021 / 1\nу рівняннях (14), (15) і (18)\u2013(20), тобто такі \nпроміжки ставляться з тире без пробілів, які \nмають таку форму: \nˆ( ) ( ; , )I d= Ν∫ xxg x x x P x,          (24)","content_01":"де ˆ( ) ( ; , )I d= Ν∫ xxg x x x P x \u2013 багатовимірний Гаусів розподіл \nіз вектором середніх значень ˆ( ) ( ; , )I d= Ν∫ xxg x x x P x і коваріаційною \nматрицею вектора стану ˆ( ) ( ; , )I d= Ν∫ xxg x x x P x. Три апроксима-\nції для обчислення інтеграла (24) розглянуто \nв [16]. Із них можна обрати прийнятний для \nконкретної реалізації варіант. \nГранулярний фільтр \nРозглянемо варіант реалізації ймовірніс-\nного Баєсового фільтра, який отримав назву \nгранулярного (particle filter). Завданням мето-\nду ГФ є апроксимація апостеріорної щільності \nрозподілу невідомого стану за наявності вимі-\nрів, тобто потрібно оцінити P x k z k[ ( ) | ( : )]1 . Є \nкілька алгоритмів ГФ, що ґрунтуються на ме-\nтоді Монте-Карло для генерування псевдови-\nпадкових послідовностей, які використовують \nдля оцінювання розподілів випадкових вели-\nчин необхідних типів [17\u201319].\nАлгоритм генерування послідовної вибірки \nза значимістю. Алгоритм генерування послідов-\nної вибірки за значимістю (Sequential Importance \nSampling, або SIS Algorithm) є методом реалізації \nрекурсивного Баєсового фільтра з використан-\nням псевдовипадкової послідовності, яку задає \nметод Монте-Карло. Це базовий алгоритм ГФ. \nОсновною ідеєю є представлення бажаної апо-\nстеріорної щільності розподілу як множини \nвипадкових елементів із асоційованими ваго-\nвими коефіцієнтами для обчислення оцінок \nна основі цих згенерованих елементів і вагових \nкоефіцієнтів. За значного збільшення кількості \nелементів псевдовипадкової вибірки характе-\nристика застосування методу Монте-Карло стає \nеквівалентною звичайному функціональному \nопису апостеріорної щільності, а SIS-фільтр на-\nближається до оптимальної Баєсової оцінки. \nНехай { ( : ), ( )}x k w ki i\ni\nNs1 1=  \u2013 випадкова \nміра, що характеризує апостеріорну щільність \nP x k z k[ ( : ) | ( : )]1 1 , де { ( : ), , ,..., }x k i Ni\ns1 0 1=  \u2013 \nмножина k-крокових траєкторій руху опорних \nточок (гранул) із асоційованими нормованими \nваговими коефіцієнтами { ( ), , ,..., }w k i Ni\ns= 0 1 , \nw ki\ni\nNs\n( )=\n=∑ 1\n1\n; тут Ns \u2013 задана кількість гра-\nнул. Тепер апостеріорна щільність у момент \nчасу k може бути апроксимована так: \nP x k z k\nw k x k x ki i\nNs\n[ ( : ) | ( : )]\n( ) ( ( : ) ( : ))\n1 1\n1 1\n1\n≈\n≈ −∑ δ ,      (25)\nде d(x) \u2013 d-функція Дірака, тобто \n[ (1 : ) | (1 : )] ( )i iP x k z k w k≈ .\nВагові коефіцієнти обирають за прин-\nципом генерування вибірки за значущістю. \nПрипустимо, що P x x( ) ( )∝π  (тут \u201cP x x( ) ( )∝π\u201d означає \nпропорційність) \u2013 це щільність розподілу ви-\nпадкової величини, реалізацію якої складно \nзгенерувати з її дійсного розподілу, але для якої \nможна обчислити p(x). Нехай також xi ~ P(x), \ni = 0, ..., Ns \u2013 реалізації випадкової величини, \nщо легко генеруються з розподілу зі щільністю \nQ( )⋅ , яка називається запропонованою щільні-\nстю чи значущою щільністю (proposal density \nй importance density). Тепер зважена апрокси-\nмація щільності P( )⋅  виглядає так: \nP x w k x xi i\ni\nNs\n( ) ( ) ( ),≈ −\n=\n∑ δ\n1\nде\nw\nx\nQ x\ni\ni\ni\n∝\nπ( )\n( )\n                    (26)\nє нормованою вагою для i-ї гранули (після об-\nчислення відношення нормують вагові коефіці-\nєнти так, щоб забезпечити умову w ki\ni\nNS\n( ) =\n=\n∑ 1\n1\n).\nТепер, якщо реалізації x ki ( : )1  були зге-\nнеровані з розподілу із запропонованою щіль-\nністю Q x k z k[ ( : ) | ( : )]1 1 , то вагові коефіцієнти \nв (25), відповідно до виразу (26), визначимо так: \nw\nP x k z k\nQ x k z k\ni ∝\n[ ( : ) | ( : )]\n[ ( : ) | ( : )]\n1 1\n1 1\n.          (27)\nУ випадку послідовних обчислень, \nмаючи на кожній ітерації зважену вибір-\nку, що апроксимує апостеріорну щіль-\nність P x k z k[ ( : ) | ( : )]1 1 1 1- - , можна було б \nапроксимувати P x k z k[ ( : ) | ( : )]1 1  новою вибір-\nкою. Але, якщо запропонована щільність обра-\nна так, що вона розкладається на множники: \nQ x k z k\nQ x k x k z k\nQ x k z k\n[ ( : ) | ( : )]\n[ ( ) | ( : ), ( : )]\n[ ( : ) | ( :\n1 1\n1 1 1\n1 1 1\n=\n= −\n− −1)],\n23ІНФОРМАЦІЙНІ ТЕХНОЛОГІЇ, СИСТЕМНИЙ АНАЛІЗ ТА КЕРУВАННЯ\nто можна отримати елементи x k P x k z ki ( : ) [ ( : ) | ( : )]1 1 1~\nx k P x k z ki ( : ) [ ( : ) | ( : )]1 1 1~ , доповнюючи кожен \nіз наявних елементів вибірки x k P x k z ki ( : ) [ ( : ) | ( : )]1 1 1 1 1 1− ∼ − −\nx k P x k z ki ( : ) [ ( : ) | ( : )]1 1 1 1 1 1− ∼ − −  новою оцінкою стану \nx k P x k x k z ki ( ) [ ( ) | ( : ), ( : )]∼ −1 1 1 . \nУ практичних застосуваннях найчасті-\nше вимагають лише фільтровану оцінку роз-\nподілу P x k z k( ( ) | ( : ))1  на кожному кроці, \nа не умовний розподіл одразу всієї траєкторії \nP x k z k( ( : ) | ( : ))1 1 . Тому надалі будемо розгля-\nдати саме цей випадок.\nВикористовуючи прямий наслідок із теоре-\nми Баєса:\nP x k z k\nP z k x k P x k z k\nP z k z k\n( ( ) | ( : ))\n( ( ) | ( )) ( ( ) | ( : ))\n( ( ) | ( :\n1\n1 1\n1 1\n=\n=\n−\n− ))\n,\nякщо","content_02":"Q x k x k z k\nQ x k x k z k\n( ( ) | ( : ), ( : ))\n( ( ) | ( ), ( )),\n1 1 1\n1\n− =\n= −\nтобто запропонована щільність залежить лише \nвід x(k \u2013 1) і z(k), можна показати, спираючись \nна [17, 19], що для оновлення вагових коефіці-\nєнтів справедливе співвідношення: \nw k w k\nP z k x k P x k x k\nP x k x k\ni i\ni i i\ni i\n( ) ( )\n( ( ) | ( )) ( ( ) | ( ))\n( ( ) | ( ),\n∝ −\n−\n−\n1\n1\n1 z k( ))\n,  \n    (28)\nа фільтрований апостеріорний розподіл може \nбути апроксимований так:\nP x k z k w k x k x ki i\ni\nNS\n( ( ) | ( : )) ( ) ( ( ) ( )).1\n1\n≈ −\n=\n∑ δ  (29)\nНеобхідно підкреслити, що вагові коефі-\nцієнти wi(k) мають бути нормовані так, щоб \nw ki\ni\nNS\n( ) .=\n=\n∑ 1\n1\n Вибір запропонованого розподілу \nє одним із найважливіших етапів проєктуван-\nня гранулярного фільтра. Водночас можливі \nваріанти вибору, переваги та недоліки яких \nрозглянуті в [17, 19]. Зокрема, важливо, щоб \nдисперсія вагових коефіцієнтів, wi(k), була не-\nзначною. Часто як запропонований розподіл \nвикористовують апріорний розподіл даних:\nQ x k x k z k P x k x ki i( ( ) | ( ), ( )) ( ( ) | ( )),− = −1 1  (30)\nщо, очевидно, є досить зручним варіантом ви-\nбору. В такому разі (28) спрощують до\nw k w k P z k x ki i i( ) ( ) ( ( ) | ( )).∝ −1        (31)\nОднак такий вибір запропонованого роз-\nподілу є найкращим не в усіх задачах.\nОсновний алгоритм. Підсумуємо форму-\nлювання алгоритму послідовного генерування \nвибірки за значущістю. Елементи xi(1 : 1) у зва-\nженій вибірці на першому кроці { ( : ), }x\nN\ni\nS\ni\nNS1 1\n1\n1=","content_03":"генеруються з початкового розподілу P(x(1)). \nОскільки цей розподіл істинний, то виконувати \nкорегування значень непотрібно, та всі вагові \nкоефіцієнти мають бути однаковими, тобто\nw\nN\ni\nS\n( ) .1\n1\n=\nМаючи зважену вибірку на (k \u2013 1)-му кроці, \nпроцедуру генерування зваженої вибірки на k-му \nкроці можна представити псевдокодом: \nAlgorithm 1: SIS Particle Filter\n[{ ( ), ( )} ]x k w ki i\ni\nNS\n=1  = \n= SIS [{ ( ), ( )} , ( )]x k w k z ki i\ni\nNS− − =1 1 1\nFOR\n\u2014 Згенерувати x k q x k x k z ki i( )~ ( ( ) | ( ), ( )).-1\n\u2014 Присвоїти гранулі xi(k) вагу wi(k), \nвідповідно до (28)\nEND FOR\nДля цього та всіх подальших алгоритмів \nфільтрації на кожному кроці апостеріорний роз-\nподіл можна апроксимувати за формулою (29). \nОцінкою умовного математичного сподівання \nстану x(k) буде\n1\nˆ( ) ( ) ( ).\nSN\ni i\ni\nx k w k x k\n=\n=∑               (32)\nПовторне генерування (відсіювання) гранул. \nЗа реалізації SIS гранулярного фільтра часто \nвиникає проблема виродження вагових кое-\nфіцієнтів, коли після певної кількості ітерацій \nусі гранули, крім однієї, мають незначну вагу. \nОскільки дисперсія вагових коефіцієнтів може \nз часом лише збільшуватись, то феномену ви-\nродження уникнути неможливо [17, 19, 20]. \nТаке виродження спричинено витратою знач-\nної частини обчислень на оновлення гранул, \n24 KPI Science News 2021 / 1\nвнесок яких в апроксимований розподіл \nP x k z k( ( ) | ( : ))1  майже нульовий.\nОдним зі способів зменшення ефекту ви-\nродження є повторне генерування псевдовипад-\nкових значень (resampling). Основною ідеєю пов-\nторного генерування є виключення з розгляду \nгранул із незначною вагою та фокусування уваги \nна гранулах із великою. На цьому кроці гене-\nрують нову множину значень { ( )}*x ki\ni\nNS\n=1 , тобто \nгенерується вибірка (із повтореннями) NS реалі-\nзацій випадкової величини x(k) із наближеного \nдискретного розподілу P x k z k( ( ) | ( : ))1 , задано-\nго виразом (29), так, що P x k x k w ki j j{ ( ) ( )} ( ).* = =  \nОтримана вибірка є насправді вибіркою неза-\nлежних однаково розподілених (н.о.р. або i.i.d.) \nвеличин із дискретного розподілу (29), тому ва-\nгові коефіцієнти встановлюються нині рівними \nтакій величині: \nw k\nN\ni\nS\n( ) .=\n1\nНаведемо псевдокод повторного гене-\nрування. Такий варіант генерування чи сис-\nтематичне генерування (systematic resampling) \nобрано через простоту реалізації та оцінюван-\nня складності алгоритму O(NS). Водночас для \nкожного елементу нової вибірки зберігається \nйого індекс у попередній вибірці i j, що знадо-\nбиться в таких алгоритмах.\nAlgorithm 2: Resampling Algorithm\n[{ ( ), ( ), } ]*x k w k ij j j\nj\nNS\n=1  = \n= RESAMPLE [{ ( ), ( )} ]x k w ki i\ni\nNS\n=1\nІніціалізувати функцію розподілу (ФР): c(1) = 0\nFOR i N S= 2,\n\u2014 Побудувати ФР: c i c i w ki( ) ( ) ( )= − +1\nEND FOR\nПочати спочатку ФР: i = 1\nЗгенерувати початкову точку: u U NS( ) [ , ].1 0 1∼ −\nFOR j N S= 1,\n\u2014 Рухатись уздовж ФР: u j u N jS( ) ( ) ( )= + −−1 11\n\u2014 WHILE u j c i( ) ( )\n\u2014 \u2014 i = i + 1\n\u2014 END WHILE\n\u2014 Присвоїти елемент: x k x kj i*( ) ( )=\n\u2014 Присвоїти вагу: w k Nj\nS( ) = −1\n\u2014 Присвоїти основне (батьківське) \nзначення: i j\n = i\nEND FOR\nПовторне генерування має недоліки. \nПо-перше, воно звужує можливості паралеліз-\nму, оскільки на кроці відсіювання всі гранули \nмають комбінуватися. По-друге, гранули з ве-\nликою вагою будуть обиратися багаторазово, \nщо може призвести до втрати різноманітності \nвибірки, тобто результуюча вибірка міститиме \nбагато повторів. Ця проблема відома як збід-\nніння вибірки (sample impoverishment); вона є \nособливо гострою в разі малого шуму (коли-\nвань) процесу. Тоді всі гранули можуть зліпи-\nтися воєдино через кілька ітерацій. \nФільтр на основі генерування вибірки \nза значущістю з відсіюванням. Фільтр на основі \nгенерування вибірки за значущістю з відсію-\nванням (Sampling Importance Resampling Filter \n(SIR)) \u2013 це метод Монте-Карло, який можна \nзастосовувати до задач рекурсивної Баєсової \nфільтрації. Обмеження, накладені на його ви-\nкористання, є дуже слабкими. Функції f ( , )⋅ ⋅  \nі h ( , )⋅ ⋅  у моделях (1) і (2) мають бути відоми-\nми, необхідно мати змогу генерувати реаліза-\nції псевдовипадкових послідовностей із розпо-\nділу шуму P v k( ( ))-1  й апріорного розподілу \nP x k x k( ( ) | ( ))-1  та визначати щільність роз-\nподілу P z k x k( ( ) | ( ))  у потрібних точках, при-\nнаймні з точністю до спільної константи. \nSIR-алгоритм можна легко вивести з алго-\nритму SIS відповідним вибором таких величин:\n1.1Насамперед запропонованого розпо-\nділу Q x k x k z ki( ( ) | ( ), ( ))-1  \u2013 ним обирається \nапріорна щільність P x k x ki( ( ) | ( ))-1 .\n2. Кроку відсіву, який здійснюється в ко-\nжен момент часу. Такий вибір запропонованого \nрозпо ділу зумовлює необхідність генерування \nреалізацій із P x k x ki( ( ) | ( ))-1 . Реалізацію \nx k P x k x ki i( ) ( ( ) | ( ))∼ −1  можна отримати, \nякщо згенерувати реалізацію шуму v k P v ki ( ) ( ( ))− ∼ −1 1 \nv k P v ki ( ) ( ( ))− ∼ −1 1 , а покласти x k f x k v ki i i( ) ( ( ), ( ))= − −1 1\nx k f x k v ki i i( ) ( ( ), ( ))= − −1 1 .\nДля такого спеціального вибору запропо-\nнованої щільності формула оновлення вагових \nкоефіцієнтів набуває вигляду (31). Але, взявши \nдо уваги, що відсів відбувається в кожен мо-\nмент часу, отримуємо: w k N ii\nS( ) / ),− = ∀1 1 , \nа тому\nw k P z k x ki i( ) ( ( ) | ( )).∝             (33)\n25ІНФОРМАЦІЙНІ ТЕХНОЛОГІЇ, СИСТЕМНИЙ АНАЛІЗ ТА КЕРУВАННЯ\nВагові коефіцієнти, задані в (33), норму-\nються перед фазою відсіювання. Псевдокод \nітерації цього алгоритму такий:\nAlgorithm 3: SIR Particle Filter\n[{ ( ), ( )} ]x k w ki i\ni\nNS\n=1  = SIR[{ ( ), ( )} , ( )]x k w k z ki i\ni\nNS\n=1\nFOR i N S= 1,\n\u2014 Згенерувати x k p x k x ki i( ) ( ( ) | ( ))∼ −1\n\u2014 Обчислити w k p z k x ki i( ) ( ( ) | ( ))=\nEND FOR\nОбчислити загальну вагу: t w ki\ni\nNS\n=\n=\n∑ ( )\n1\nFOR i N S= 1,\n\u2014 Нормувати i-ту вагу: w k t w ki i( ) ( )= −1\nEND FOR\nПровести відсів, використовуючи Algorithm 2 \n(Resampling Algorithm):\n\u2014 [{ ( ), ( ), } ]x k w ki i\ni\nNS− =1\n = \n= RESAMPLE [{ ( ), ( )} ]x k w ki i\ni\nNS\n=1\nДопоміжний фільтр генерування вибірки \nза значущістю з відсіюванням. Допоміжний \nфільтр генерування вибірки за значущістю \nз відсіюванням (Auxiliary Sampling Importance \nResampling Filter (ASIR)) є варіантом стан-\nдартного алгоритму фільтрації вибірки за зна-\nчущістю з відсіюванням. Його можна отри-\nмати з SIR-фільтра введенням запропонованої \nщільності Q x i zk k( , | ):1 , із якої генеруються \nреалі зації пар { ( ), }x k ij j\nj\nNS\n=1 , де ij позначає но-\nмер гранули в (k \u2013 1)-й момент. Значення ij \nу цьому фільтрі називають допоміжною змін-\nною, оскільки її єдина мета \u2013 допомогти \nреалізувати задачі імітації. \nВикористовуючи теорему Баєса, покажемо:\nP x k i z k P z k x k\nP x k x k w ki i\n( ( ), | ( : )) ( ( ) | ( ))\n( ( ) | ( )) ( ).\n1\n1 1\n∝\n− −      (34)\nASIR-фільтр генерує реалізацію зі спіль-\nного розподілу, P x k i z k( ( ), | ( : ))1 , а потім \nопус кає номер i у парі (x(k), i), щоб отримати \nвибірку { ( )}x kj j\nNS\n=1  з маргінального розподілу \nP x k z k( ( ) | ( : )).1  Запропонована щільність для \n{ ( ), }x k ij j\nj\nNS\n=1  має задовольняти пропорційності:\nQ x k i z k P z k k\nP x k x k w k\ni\ni i\n( ( ), | ( : )) ( ( ) | ( ))\n( ( ) | ( )) ( ),\n1\n1 1\n∝\n− −\nµ\n    (35)\nде mi(k) \u2013 певна характеристика x(k) за умови \nxi(k \u2013 1). Наприклад, це може бути умовне ма-\nтематичне сподівання µi ik E x k x k( ) [ ( ) | ( )]= −1 , \nмода чи реалізація µi ik P x k x k( ) ( ( ) | ( )).∼ −1  \nЯкщо записати \nQ x k i z k\nQ x k i z k P i z k\n( ( ), | ( : ))\n( ( ) | , ( : )) ( | ( : )),\n1\n1 1\n=\n=\nі покласти\nQ x k i z k P x k x ki( ( ) | , ( : )) ( ( ) | ( )),1 1= −\nто з (35) випливає:\nQ i z k P z k k w ki i( | ( : )) ( ( ) | ( )) ( ).1 1∝ −µ   (36)\nПарі { ( ), }x k ij j\nj\nNS\n=1  присвоюється вага, про-\nпорційна відношенню (34) і (35):\nw k\nP z k x k\nP z k k\ni\nj\ni j\n( )\n( ( ) | ( ))\n( ( ) | ( ))\n.∝\nµ\n           (37)\nПсевдокод ітерації цього алгоритму: \nAlgorithm 4: Auxiliary Particle Filter\n{ ( ), ( )}x k w ki i\ni\nNS\n=1  = \n= APF [{ ( ), ( )} , ( )]x k w k z ki i\ni\nNS− − =1 1 1\nFOR i N S= 1,\n\u2014 Обчислити mi(k)\n\u2014 Обчислити \nw k q i z k p z k k w ki i i( ) ( | ( : )) ( ( ) | ( )) ( ).= ∝ −1 1µ\nEND FOR\nОбчислити загальну вагу: t w ki\ni\nNS\n=\n=\n∑ ( )\n1\nFOR i N S= 1,\n\u2014 Нормувати i-ту вагу: w k t w ki i( ) ( )= −1\nEND FOR\nПровести відсів, використовуючи Algo-\nrithm 2 (Resampling Algorithm):\n\u2014 [{ , , } ]− − =i j j\nNS\n1\n = \n= RESAMPLE [{ ( ), ( )} ]x k w ki i\ni\nNS− =1 1\nFOR j N S= 1,\n\u2014 Згенерувати x k q x k i z k p x k x kj j i j( ) ( ( ) | , ( : )) ( ( ) | ( ))∼ = −1 1\nx k q x k i z k p x k x kj j i j( ) ( ( ) | , ( : )) ( ( ) | ( ))∼ = −1 1 , як у SIR-фільтрі\n\u2014 Присвоїти вагу wi(k), використовуючи (15)\nEND FOR\nОбчислити загальну вагу: t w ki\ni\nNS\n=\n=\n∑ ( )\n1\n26 KPI Science News 2021 / 1\nFOR i N S= 1,\n\u2014 Нормувати i-ту вагу: w k t w ki i( ) ( )= −1\nEND FOR\nЩоб згенерувати реалізацію з розподілу \nP x k i z k( ( ), | ( : ))1 , спочатку генерують номер i \nіз імовірністю w k Q i z ki ( ) ( | ( : ))∝ 1  (це ймовір-\nності першого етапу), а потім x(k) із розподі-\nлу P x k x ki( ( ) | ( )).-1  Після цього індекс i від-\nкидають, а x(k) присвоюють ваги, відповідно \nдо (37), тобто вагові коефіцієнти другого етапу. \nВодночас є сподівання, що отримані вагові кое-\nфіцієнти другого рівня мають меншу дисперсію, \nніж ваги в оригінальному SIR-алгоритмі.\nРегуляризований гранулярний фільтр. Метод \nвідсіювання введено для зменшення ефекту \nвиродження результату на виході фільтра, що є \nпроблемою для гранулярних фільтрів. Але, як \nбуло зазначено в його обговоренні, відсіювання \nпризводить до інших проблем, зокрема пробле-\nми втрати різноманітності гранул. Вона вини-\nкає, бо на кроці відсіювання реалізації псевдо-\nвипадкових значень генеруються з дискретного, \nа не неперервного розподілу. Якщо не акцен-\nтувати на цій проблемі, вона може призвести \nдо екстремального випадку \u201cзліплювання гра-\nнул\u201d, коли всі Ns гранул знаходяться в тому \nсамому секторі простору станів і погано відо-\nбражають шуканий апостеріорний розподіл.\nДля боротьби з цією проблемою запропо-\nновано регуляризований гранулярний фільтр \n(Regularized Particle Filter (RPF)). У ньому \nза відсіювання генеруються гранули з не-\nперервної p x k z k( ( ) | ( : ))1 , а не з дискретної \nапроксимації, як у SIR-фільтрі. А саме такої \nапроксимації: \nP x k z k w k K x k x ki\nh\ni\ni\nNS\n( ( ) | ( : )) ( ) ( ( ) ( )),1\n1\n≈ −\n=\n∑  (38)\nде\nK x\nh\nK\nx\nhh nx\n( ) ;= \n\n\n\n\n\n1\n             \n (39)\nмасштабоване статистичне ядро щільності роз-\nподілу (kernel density) K ( )⋅ ; h > 0 \u2013 параметр \nзгладжування (скалярний); nx \u2013 розмірність \nвектора стану x; w k i Ni S( ), , ...,= 1  \u2013 нормова-\nні вагові коефіцієнти. Статистичне ядро K ( )⋅  \u2013 \nце симетрична функція щільності розподілу, що: \nx K x dx x K x dx( ) , ( ) .= < ∞∫∫ 0 2|| ||\nТобто випадковий вектор зі щільністю K ( )⋅  \nмає нульове математичне сподівання та скін-\nченні моменти другого порядку.\nСтатистичне ядро K ( )⋅  і параметр зглад-\nжування h > 0 обираються так, щоб мінімізу-\nвати середнє інтегроване квадратичне відхи-\nлення (mean integrated square error (MISE)) між \nсправжньою апостеріорною щільністю та від-\nповідним регуляризованим емпіричним пред-\nставленням у (38), яке визначається так: \n2\nˆ ˆ( ) [ ( ( ( ) | (1 : ))\n( ( ) | (1 : )) ( )],\nMISE p E p x k z k\np x k z k dx k\n= −\n−\n∫\nде розподіл ˆ( ( ) | (1 : ))p x k z k  позначає апрокси-\nмацію, визначену в (38). У спеціальному ви-\nпадку, коли всі елементи мають однакову ва гу \n1\nNS\n, оптимальним вибором ядра є ядро Єпа-\nнечнікова: \nK x\nn\nc\nx x\ni\ne\nx\nnx( )\n( ),\n,\n,=\n+\n− <\n\n\n\n\n2\n2\n1 1\n0\n2|| || || ||якщо\nнакше\n (40)\nде cnx  \u2013 об\u2019єм одиничної гіперсфери в просто-\nрі Rnx . Часто зручно використовувати Гаусове \nядро: \nK x en\nn\nxx\n( ) ( ) .\n|| ||\n=\n− −\n2 2\n1\n2\n2\nπ              (41)\nДо того ж, якщо щільність, що апрокси-\nмується, є Гаусовою з одиничною коваріацій-\nною матрицею, то оптимальним вибором па-\nраметра згладжування є:\nh A K Nopt S\nnx= +( ) ,/( )1 4               (42)\nде A K c ne n x\nn n\nx\nx x( ) [ ( )( ) ] /( )= +− +8 4 21 1 4π  для ядра \nЄпанечнікова та A K nn x\nnx( ) [ / ( )] /( )= + +4 2 1 4  для \nГаусового ядра [19].\nВ алгоритмі регуляризованого гранулярно-\nго фільтра відсіювання проводять не на кожно-\nму кроці, а тоді, коли значення міри вироджен-\nня стає нижчим деякого заданого порогу NT . \nМіра виродження обчислюється:\nN\nw k\neff\ni\ni\nNS\n=\n=∑\n1\n2\n1\n( ( ))\n.              (43)\n27ІНФОРМАЦІЙНІ ТЕХНОЛОГІЇ, СИСТЕМНИЙ АНАЛІЗ ТА КЕРУВАННЯ\nЗазначимо: якщо встановити порогове \nзначення NT рівним NS, то відсіювання відбу-\nватиметься на кожній ітерації алгоритму.\nПсевдокод ітерації алгоритму: \nAlgorithm 5: Regularized Particle Filter\n[{ ( ), ( )} ]*x k w ki i\ni\nNS\n=1  = \n= RPF[{ ( ), ( )} , ( )]x k w k z ki i\ni\nNS− − =1 1 1\nFOR i N S= 1,\n\u2014 Згенерувати x k q x k x k z ki i( ) ( ( ) | ( ), ( ))∼ −1\n\u2014 Присвоїти гранулі xi(k) вагу wi(k), \nвідповідно до (6)\nEND FOR\nОбчислити загальну вагу: t w ki\ni\nNS\n=\n=∑ ( )\n1\nFOR i N S= 1,\n\u2014 Нормувати i-ту вагу: w k t w ki i( ) ( )= −1\nEND FOR\nОбчислити Neff\n , використовуючи (21)\nIF Neff < NT \n\u2014 Обчислити емпіричну коваріаційну \nматрицю S(k) для { ( ), ( )}x k w ki i\ni\nNS\n=1\n\u2014 Обчислити матрицю ( ) ( ) ( )k k S kT∑ ∑ = таку,","content_04":"що ( ) ( ) ( )k k S kT∑ ∑ =\n(наприклад, ( ) ( ) ( )/k E k D k∑ = 1 2 , де","content_05":"S(k) = E(k)D(k)ET(k) \u2013 \nспектральний розклад матриці S(k))\n\u2014 Провести відсіювання, використовуючи \nAlgorithm 2 (Resampling Algorithm:\n\u2014 \u2014 [{ ( ), ( ), } ]x k w ki i\ni\nNS− =1  = RESAMPLE \n[{ ( ), ( )} ]x k w ki i\ni\nNS\n=1\n\u2014 FOR i N S= 1,\n\u2014 \u2014 Згенерувати ei ~ K зі статистичного ядра \n(використати (18) чи (19))\n\u2014 \u2014 x k x k h ki i\nopt\ni*( ) ( ) ( )= + ∑ ε  \n(використати (20))\n\u2014 END FOR\nEND IF\nХоча результати (40)\u2013(42) є оптимальни-\nми лише в окремих випадках, їх можна вико-\nристовувати в загальному випадку для отри-\nмання субоптимального фільтра.\nВведення регуляризації покращує ре-\nзультат, як порівняти зі звичайним SIR-філь-\nтром, коли є значна втрата різноманітності ви-\nбірки гранул, наприклад, якщо шум у процесі \nє невеликим. Однією з проблем такого підходу \nє збільшення дисперсії апостеріорного роз-\nподілу.\nДля глибшого аналізу властивостей алго-\nритмів ГФ, вибору запропонованих розподілів, \nаналізу збіжності процесів генерування вибі-\nрок, точного виведення формул тощо необхід-\nно звернутись до [14\u201320].\nПриклад: локалізація робота. Розглянемо \nописану модель й алгоритми ГФ на варіанті \nзадачі глобальної локалізації мобільних роботів \n(global localization for mobile robots) або задачі \nпро викраденого робота (hijacked robot problem). \nУ загальному варіанті вона полягає у визна-\nченні положення робота за даними з сенсора. \nЦя задача була розв\u2019язана низкою ймовірніс-\nних методів наприкінці 1990-х \u2013 на початку \n2000-х років. Задача є важливою та знаходить \nзастосування в мобільній робототехніці та про-\nмисловості [20\u201322]. Схожими по суті є задачі \nпозиціювання підводних човнів, літальних апа-\nратів, автомобілів тощо. \nРозглянемо задачу позиціювання робота [23]. \nНехай у темному лабіринті ввімкнувся робот. \nВін має мапу лабіринту та компас. У лабіринті \nв деяких точках встановлено позначені на мапі \nстанції, що можуть приймати та відбивати сиг-\nнал. Робот не знає, в якому місці лабіринту \nзнаходиться, але може в кожен момент часу \nвідправляти сигнал і з певною похибкою дізна-\nватися відстань до найближчої станції. Робот \nпочинає блукати лабіринтом, роблячи кожен \nкрок у новому випадково обраному напрямку, \nале його компас також дає певну несистема-\nтичну похибку. На кожному кроці робот ви-\nзначає відстань до найближчої станції. Мета \nдослідження: оцінити координати робота в ла-\nбіринті в системі відліку, введеній на мапі.\nПереведемо цю задачу в модель у просторі \nстанів. Невідомим станом робота, який необ-\nхідно оцінити за допомогою ГФ, є пара його \nкоординат на k-му кроці (x(k), y(k). Вимірю-\nваною змінною z(k) є відстань до найближчої \nстанції на поточному кроці. Так, маємо систему \nрівнянь:\nx k\ny k\nx k\ny k\nL\nk\nk\n( )\n( )\n( )\n( )\ncos( ( ))\nsin( ( ))\n\n\n\n\n\n =\n−\n−\n\n\n\n\n\n +\n−\n−\n1\n1\n1\n1\nθ\nθ\n\n\n\n    (44)\nz k\nx k\ny k\nx\ny\nk( )\n( )\n( )\n( ),\n*\n*\n=\n\n\n\n\n\n −\n\n\n\n\n\n + ν          (45)\nде L \u2013 довжина кроку робота; θ θ θ( ) ( ( ) / , ( ) / )k U k k∼ − +0 02 2∆ ∆ \nθ θ θ( ) ( ( ) / , ( ) / )k U k k∼ − +0 02 2∆ ∆  \u2013 кут повороту робота \n28 KPI Science News 2021 / 1\nв радіанах на k-му кроці. Він є рівномірно \nрозподіленим, враховуючи похибку компа-\nса, в інтервалі з центром q0( )k  \u2013 випадково \nвибраним на цей крок значенням кута пово-\nроту, з огляду на покази компаса θ π( ) [ ; ];k ∈ 0 2  \n( , )* *x y  \u2013 координата найближчої до робота \nстанції; ν σ( ) ( , )k N∼ 0 2  \u2013 похибка вимірювання \nвідстані до найближчої станції. \nЗастосування гранулярних фільтрів. Для \nзастосування гранулярних фільтрів знадоблять-\nся такі розподіли даних: p(x(k), k y k x k y k( ), ( ) | ( ), ( )),- -1 1 \np x k y k x k y k( ( ), ( ) | ( ), ( )),- -1 1  p z k x k y k( ( ) | ( ), ( )).\nОчевидно, що\np z k x k y k\nN\nx k\ny k\nx\ny\n( ( ) | ( ), ( ))\n( )\n( )\n, .\n*\n*\n=\n=\n\n\n\n\n\n −\n\n\n\n\n\n\n\n\n\n\n\nσ2           (46)\nРозглянемо розподіл p x k y k x k y k( ( ), ( ) | ( ), ( )).- -1 1 p x k y k x k y k( ( ), ( ) | ( ), ( ).- -1 1\np x k y k x k y k( ( ), ( ) | ( ), ( )).- -1 1  Із геометричних міркувань видно: \nякщо кут повороту робота розподілений рів-\nномірно на відрізку, то координата (x(k), (y(k)) \nпісля кроку буде належати відповідній дузі \nз центром у точці (x(k \u2013 1), (y(k \u2013 1)) і радіусом L. \nЗа такої умови (x(k), (y(k)) має рівномір-\nний розподіл на дузі:\np x k y k x k y k\nL\nx k y k i\ni\n( ( ), ( ) | ( ), ( ))\n, ( ( ), ( ))\n,\n− − =\n=\n∈\n1 1\n1\n2\n0\nπ\nдуз\nнакше\n\n\n\n.\nГенерування стану (x(k), (y(k)) з розподілу \np x k y k x k y k( ( ), ( ) | ( ), ( )).- -1 1 p x k y k x k y k( ( ), ( ) | ( ), ( )).- -1 1 p x k y k x k y k( ( ), ( ) | ( ), ( ).- -1 1  можна виконува-\nти безпосередньо, а саме згенерувати реалізацію \nвипадкової величини θ( )k −1 , яка має рівномір-\nний розподіл U k k( ( ) / , ( ) / ),θ θ0 01 2 1 2− − − +∆ ∆  \nй обчислити (x(k), (y(k)) із (44).\nОскільки попередньої інформації щодо \nположення робота немає, початкова коорди-\nната (x(1), (y(1)) є рівномірно розподіленою \nвеличиною по вільній від перешкод області ла-\nбіринту. В цій задачі гранули { ( )}x ki i\nNS\n=1 по суті \nвідповідають гіпотезам про координату робота. \nЗадача полягає в знаходженні на кожному кро-\nці розподілу ймовірностей для всіх можливих \nположень робота на мапі.\nУ наданій програмі для імітаційного моде-\nлювання поставленої задачі реалізується ГФ за-\nдля визначення стану робота за обраним мето-\nдом [23]. Доступними операціями є: фільтрація \nвибірки даних за значущістю з відсіюванням \n(SIR), допоміжний фільтр вибірки за значущі-\nстю з відсівом (APF) і регуляризований гра-\nнулярний фільтр (RPF). Базовий алгоритм по-\nслідовного генерування вибірки за значущістю \n(SIS) у чистому вигляді не використовують че-\nрез проблему виродження вагових коефіцієнтів. \nМетоди реалізовані відповідно до наведеного \nпсевдокоду з такими уточненнями:\n1. За обчислення розподілу p z k x k y k( ( ) | ( ), ( )). \ny(k)) за формулою (24) для гранул, координати \nяких (x(k), (y(k)) знаходяться поза лабіринтом, \nотримане значення штрафується \u2013 множиться \nна емпіричний коефіцієнт 0,5. Так зменшуєть-\nся вага тих гранул, які завідомо не відповідають \nточному положенню робота.\n2. В APF-фільтрі як mi(k) використовують \nреалізацію з перехідного розподілу стану робо-\nта: µi i ik p x k y k x k y k( ) ( ( ), ( ) | ( ), ( ))∼ − −1 1 . Тоді \nрозподіл ( ( ) | ( ))ip z k kμ  також має форму (24).\n3. У RPF як запропонований розподіл \nq(x(k) q x k y k x k y k z ki i( ( ), ( ) | ( ), ( ) ( ))- -1 1  використову-\nють апріорний p x k y k x k y ki i( ( ), ( ) | ( ), ( ))- -1 1 .\n4. У RPF як статистичне ядро використо-\nвують Гаусове ядро в двовимірному просторі, \nоскільки для нього зручно генерувати реаліза-\nції e.\n5. У RPF порогове значення NT емпірично \nобране рівним 0,2NS (коефіцієнт можна зміни-\nти як константу в коді програми). \nПрограмна реалізація поставленої задачі \nподана в [23]. Унаслідок обчислювальних екс-\nпериментів встановлено, що координати робота \nв лабіринті в системі відліку, введеній на мапі, \nвизначаються з прийнятною для використання \nточністю. Так, ймовірнісний Баєсовий фільтр \nможе бути використаний для слідкування \nза розташуванням рухомих об\u2019єктів. Очевид-\nно, що поданий вище приклад \u2013 це лише одне \nз можливих застосувань методів імовірнісної \nфільтрації. Задачі розглянутого типу доціль-\nно розв\u2019язувати за допомогою спеціалізованих \nСППР, які створюються на множині методів \nпопередньої обробки даних, моделювання, про-\nгнозування та генерування альтернативних (ке-\nрівних) впливів. Системи такого типу надають \nможливість оперативно розглянути різні (до-\nпустимі) варіанти знаходження розв\u2019язків по-\nставлених задач за множиною вибраних методів \nй обрати кращий (прийнятний) варіант для по-\nдальшого практичного використання, зокрема \nв реальному часі. Водночас на кожному етапі \nобчислень потрібно використовувати множину \nстатистичних критеріїв якості, які забезпечать \n29ІНФОРМАЦІЙНІ ТЕХНОЛОГІЇ, СИСТЕМНИЙ АНАЛІЗ ТА КЕРУВАННЯ\nвисокоякісні проміжні й остаточні результати \nаналізу даних. \nВисновки \nПодано короткий огляд сучасних мето-\nдів оптимальної та ймовірнісної фільтрацій \nданих. Зокрема, це лінійні та нелінійні алго-\nритми фільтрації Калмана та варіанти реаліза-\nції ймовірнісного Баєсового фільтра, який де-\nдалі більше застосовують для розв\u2019язання задач \nзгладжування даних, оцінювання компонент \nвектора стану, що не вимірюються, та корот-\nкострокового прогнозування. Ймовірнісні ме-\nтоди обробки даних мають деякі переваги перед \nвідомими статистичними процедурами, а саме: \nавтоматично враховують невизначеності ймо-\nвірнісного та амплітудного типів; можуть бути \nзастосовані для аналізу нелінійних нестаціонар-\nних процесів, які трапляються практично в усіх \nгалузях досліджень; дані можуть бути неперерв-\nними чи дискретними. Подані обчислювальні \nпроцедури можуть бути успішно застосовані \nдля побудови алгоритмів фільтрації та коротко-\nстрокового прогнозування за статистичними чи \nекспериментальними даними. \nРеалізацію поданих вище методів філь-\nтрації доцільно виконувати в межах спеціалі-\nзованої СППР, яка надасть можливість вибору \nта застосування кращого для конкретного ви-\nпадку методу фільтрації на основі імітаційного \nмоделювання наявних методів і вибору найе-\nфективнішого з них для конкретних даних \nі постановки задачі. Саме СППР призначена \nдля прискореного аналізу можливостей реалі-\nзованих у системі методів фільтрації, а також \nметодів оцінювання структури та параметрів \nматематичних моделей і методів формуван-\nня альтернативних рішень на основі оцінок \nпрогнозів. Апробовані в межах СППР мето-\nди фільтрації та моделювання надалі можна \nпереносити в системи реального часу. Такий \nпідхід відповідає концепціям побудови СППР \nі підвищенню ефективності їх використання. \nВисока якість проміжних й остаточних результа-\nтів аналізу даних у СППР забезпечується множи-\nнами критеріїв якості: критеріями якості даних \n(інформативність, структурованість, повнота \nтощо), критеріями адекватності математичних \nмоделей, що будуються за наявними статис-\nтичними (експериментальними) даними, кри-\nтеріями якості прогнозів й альтернативних рі-\nшень, які ґрунтуються на обчислених оцінках \nпрогнозів. \nУ подальших дослідженнях буде розгля-\nнуто можливості застосування поданих мето-\nдів фільтрації для розв\u2019язання задач фільтра-\nції та прогнозування в межах спеціалізованих \nСППР. Також заплановано порівняльний ана-\nліз цих методів на прикладах нелінійних нес-\nтаціонарних процесів у різних галузях дослі-\nджень. \nReferences \n[1] B.D.O. Anderson and J.B. Moore, Optimal Filtering. Englewood Cliffs: Prentice-Hall, 1979, 357 p.\n[2] P.І. Bidyuk et al., Time Series Analysis. Kyiv, Ukraine: Polytechnika, 2013.\n[3] S.M. Kay, Fundamentals of Statistical Signal Processing: Estimation Theory. Upper Saddle River: Prentice Hall PTR, 1993, \n595 p. \n[4] C.K. Chui and G. Chen, Kalman Filtering with Real-Time Applications. Berlin: Springer-Verlag, 2009, 229 p. \ndoi: 10.1007/978-3-540-87849-0\n[5] S. Haykin, Adaptive Filtering Theory, 4th ed. Upper Saddle River: Prentice-Hall, 2002, 936 p.\n[6] M.Z. Zgurovskii and V.N. Podladchikov, Analytical Methods of Kalman Filtering. Kyiv, Ukraine: Naukova Dumka, 1995, 285 p.\n[7] S.J. Press, Subjective and Objective Bayesian Statistics. Hoboken: John Wiley & Sons, 2003. doi: 10.1002/9780470317105\n[8] A. Pole et al., Applied Bayesian Forecasting and Time Series Analysis. Boca Raton: Chapman & Hall/CRC, 2000. \n[9] B.P. Gibbs, Advanced Kalman Filtering, Least-Squares and Modeling. Hoboken: John Wiley & Sons, 2011, 627 p. \ndoi: 10.1002/9780470890042\n[10] J.L. Anderson, \u201cAn ensemble adjustment Kalman filter for data assimilation for data assimilation,\u201d Monthly Weather Rev., \nvol. 129, pp. 2284\u20132903, 2001. \n[11] U. Lerner et al., \u201cBayesian fault detection and diagnosis in dynamic systems,\u201d in Proc. Seventeenth National Conf. \nArtificial Intelligence, Austin, Texas, 2000, pp. 531\u2013537. \n[12] S.J. Julier and J.K. Uhlmann, \u201cUnscented filtering and nonlinear estimation,\u201d Proc. IEEE, vol. 92, no. 3, pp. 401\u2013422, 2004. \ndoi: 10.1109/JPROC.2003.823141\n[13] X. Luo and I.M. Moroz, \u201cEnsemble Kalman filters with the unscented  transform,\u201d Physica D: Nonlinear Phenomena, \nvol. 238, no. 5, pp. 549\u2013562. doi: 10.1016/j.physd.2008.12.003\n30 KPI Science News 2021 / 1\n[14] I.R. Petersen and A.V. Savkin, Robust Kalman Filtering for Signals and Systems with Large Uncertainties. Basel: Birkhäuser, \n1999, 207 p. doi: 10.1007/978-1-4612-1594-3\n[15] H.M.T. Menegaz et al., \u201cA systematization of the unscented Kalman filter theory,\u201d IEEE Trans. Autom. Control, vol. 60, \nno.10, pp. 2583\u20132598, 2015. doi: 10.1109/TAC.2015.2404511\n[16] A.J. Haug, \u201cA Tutorial on Bayesian Estimation and Tracking Techniques  Applicable to Nonlinear and Non-Gaussian \nProcesses,\u201d MITRE Corp., McLean, Virginia, MTR 05W0000004, Jan 2005. \n[17] F. Gustafsson, \u201cParticle filter theory and practice with positioning applications,\u201d IEEE Aerosp. Electron. Syst. Mag., \nvol. 25, no. 7, pp. 53\u201382, 2010. doi: 10.1109/MAES.2010.5546308\n[18] K. Ito and K. Xiong, \u201cGaussian filters for nonlinear filtering problems,\u201d IEEE Trans. Automatic Control, vol. 45, no. 5, \npp. 910\u2013927, 2000. doi: 10.1109/9.855552\n[19] M.S. Arulampalam et. al., \u201cA tutorial on particle filters for online nonlinear/non-gaussian bayesian tracking,\u201d IEEE Trans. \nSignal Process., vol. 50, no. 2, pp. 174\u2013188, 2002. \n[20] D. Fox et al., \u201cMonte Carlo localization: Efficient position estimation for mobile robots,\u201d in Proc. Sixteenth Nat. Conf. \non Artificial Intelligence and Eleventh Conference on Innovative Applications of Artificial Intelligence, Orlando, Florida, 1999, \npp. 343\u2013349. \n[21] J. Röwekämper et al., \u201cOn the position accuracy of mobile robot localization based on particle filters combined with scan \nmatching,\u201d in IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, Vilamoura-Algarve, Portugal, 2012, pp. 3158\u20133164. \ndoi: 10.1109/IROS.2012.6385988\n[22] B.W. Silverman, Density estimation for statistics and data analysis. London: Chapman & Hall, 1986, 175 p. \n[23] Particle_filter_demo [Online]. Available: https://github.com/mjl/particle_filter_demo\nР.Л. Пантеев, О.Л. Тимощук, В.Г. Гуськова, П.И. Бидюк \nМЕТОДЫ ФИЛЬТРАЦИИ ДАННЫХ В СИСТЕМАХ ПОДДЕРЖКИ ПРИНЯТИЯ РЕШЕНИЙ \nПроблематика. Большинство современных динамических процессов в экономике, финансах, экологии, технологиях \nи многих других сферах исследований имеют нелинейный нестационарный характер на коротких и длинных временных ин-\nтервалах. Поэтому для их углубленного анализа необходимо создать специализированный современный высокоразвитый \nинструментарий предварительной обработки данных, моделирования, оценивания состояний и параметров динамических \nсистем, прогнозирования их развития для использования в системах поддержки принятия решений. \nЦель исследования. Во-первых, предварительно проанализировать современные методы фильтрации статистических \nи экспериментальных данных. Рассмотреть актуальные методы фильтрации на основе вероятностного байесовского подхода \nкоторые обеспечивают возможность подготовки данных к построению адекватных моделей, вычисления высококачественных \nоценок состояний и краткосрочных прогнозов развития динамических систем в условиях стохастических возмущений и оши-\nбок измерений. \nМетодика реализации. Для реализации современных методов фильтрации используют моделирование, оптимиза-\nционные процедуры, вероятностные байесовские методы анализа данных; применяют имитационное моделирование для \nоценивания параметров и надлежащую базу на основе статистических критериев для исследования качества промежуточных \nи окончательных результатов в рамках СППР.\nРезультаты исследования. Рассмотрен ряд методов фильтрации данных, которые используют совместно с моделями, \nформально описывающими динамику выбранных процессов. Предложена методика реализации вероятностного байесовского \nфильтра, которая базируется на современных методах статистического анализа данных, включая должное применение методов \nимитационного моделирования. \nВыводы. Создание эффективных средств моделирования, оценивания состояний и прогнозирования динамики нели-\nнейных нестационарных процессов в различных областях деятельности дает возможность качественно оценивать параме-\nтры исследуемых систем и вычислять кратко- и среднесрочные прогнозы их развития. Рассмотренные средства оптимальной \nкалмановской и вероятностной байесовской фильтрации обеспечивают корректный анализ нелинейных нестационарных про-\nцессов, вычисления прогнозов и поддержку принятия управленческих решений на основе оценок прогнозов. \nКлючевые слова: анализ данных; нелинейные нестационарные процессы; методы оптимальной фильтрациии; методы \nвероятностной фильтрации; имитационное моделирование. \nR.L. Pantyeyev, O.L. Timoshchuk, V.H. Huskova, P.I. Bidyuk \nDATA FILTERING TECHNIQUES IN DECISION SUPPORT SYSTEMS\nBackground. The majority of modern dynamic processes in economy, finances, ecology, technologies and many other areas of \nstudies exhibit short- and long-term nonlinear and nonstationary behavior. That is why it is required to create for their thorough analysis \nmodern highly developed specialized instrumentation providing for appropriate preliminary statistical data processing, simulation state \nand parameter estimation and quality forecasting their evolution in time to be used in decision support systems (DSS). \nObjective. The purpose of the paper is to perform introductory analysis of some modern methods for filtering statistical and \nexperimental data; to consider modern filtering techniques on the basis of probabilistic Bayesian approach, that provide a possibility \n31ІНФОРМАЦІЙНІ ТЕХНОЛОГІЇ, СИСТЕМНИЙ АНАЛІЗ ТА КЕРУВАННЯ\nfor preparing the data to adequate simulation, computing high quality state and forecast estimates for dynamic systems in stochastic \nenvironment and availability of measurement errors. \nMethods. To implement modern data filtering techniques appropriate simulation and optimization procedures, probabilistic \nBayesian methods of data analysis are utilized; simulation algorithms for parameter estimation, and criteria bases for analyzing quality \nof intermediate and final results in the frames of DSS are used.\nResults. A set of data filtering techniques is presented to be used together with the models describing formally selected pro-\ncesses dynamics. The methodology is considered for implementation of probabilistic Bayesian filter based upon modern statistical \ndata analysis techniques including application of appropriate simulation procedures. \nConclusions. Development of effective means for simulation, state estimation and forecasting dynamics of nonlinear non-\nstationary processes in various areas of human activities provides a possibility for high quality state and parameter estimation and \ncompute short and middle term forecasts for their future evolution. The methods of optimal Kalman and probabilistic Bayesian filtering \nconsidered in the review provide a possibility for performing appropriate analysis of nonlinear nonstationary processes, compute fore-\ncasts and provide for managerial decision support on the basis of the forecast estimates. \nKeywords: data analysis; nonlinear nonstationary processes; methods of optimal filtering; methods of probabilistic filtering; \nsimulation. \nРекомендована Радою       Надійшла до редакції\nІнституту прикладного системного аналізу     18 листопада 2020 року\nКПІ ім. Ігоря Сікорського\n          Прийнята до публікації\n          29 березня 2021 року"}